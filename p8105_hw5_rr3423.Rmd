---
title: "p8105_hw5_rr3423.Rmd"
author: "Ragyie Rawal"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 10,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## PROBLEM 1 

```{r import_data}
homicide_data = read_csv("data/homicide-data.csv", na = c("", "Unknown"))
```

### Describing raw data 

```{r describing_data}
homicide_variable = 
  homicide_data %>% 
  names()

homicide_columns = 
  homicide_data %>% 
  ncol()

homicide_rows = 
  homicide_data %>% 
  nrow()
```

The **key variables** in the raw homicide dataset are `r homicide_variable`. The **number of columns** in the raw homicide dataset are `r homicide_columns`. The **number of rows** in the raw homicide dataset are `r homicide_rows`. There is data provided for a total of **`r homicide_rows` homicides** from 50 large U.S. cities. The raw dataset contained "Unknown" and blank data values, which I replaced with "NA" values when importing the csv file. 

### Creating city-state and resolution variables

```{r tidy_data}
homicide_df = 
  homicide_data %>%
  mutate(
    city_state = str_c(city, state),
    resolution = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )) %>% 
  relocate(city_state) %>% 
  filter(city_state != "TulsaAL")
```

### Summary of the total number of homicides and the number of unsolved homicides within cities

```{r summarize_cities, message = FALSE, warning = FALSE}
# summarizing total number of homicides within cities 
homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    unsolved = sum(resolution == "unsolved"), 
    total = n()
  ) %>% 
  knitr::kable(
    caption = "**Table 1: Total number of homicides and unsolved homicides within cities**")
```

### Focusing on Baltimore, MD 

```{r baltimore_analysis}
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "BaltimoreMD")

baltimore_summary = 
  baltimore_df %>% 
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  )

# prop.test to estimate proportion of unsolved homicides in baltimore 
baltimore_test = 
  prop.test(
  x = baltimore_summary %>% pull(unsolved),
  n = baltimore_summary %>% pull(n)
)

# applying broom::tidy
baltimore_test %>% 
  broom::tidy()
```

From the resulting tidy dataframe, the estimated proportion is 0.646 and the 95% confidence interval is (0.628, 0.663). This means that approximately 64.6% of homicides in Baltimore are unsolved. 

### Creating prop.test function 

```{r prop_test_function}
# creating a function 
prop_test_function = function(city_df) {
  
  city_summary = 
    city_df %>% 
    summarize(
      unsolved = sum(resolution == "unsolved"),
      n = n()
    )

  city_test = 
   prop.test(
    x = city_summary %>% pull(unsolved),
    n = city_summary %>% pull(n)
  )
  
  return(city_test)
  
}

# testing function on some cities
prop_test_function(baltimore_df)

homicide_df %>% 
  filter(city_state == "AlbuquerqueNM") %>% 
  prop_test_function
```

### Iterating across cities 

```{r iterating_cities}
# tidy dataframe with estimated proportions and CIs for each city 
results_df = 
  homicide_df %>% 
  nest(data = uid:resolution) %>%
  mutate(
    test_results = map(data, prop_test_function),
    tidy_results = map(test_results, broom::tidy)
  ) %>% 
  select(city_state, tidy_results) %>% 
  unnest(tidy_results) %>% 
  select(city_state, estimate, starts_with("conf"))
```

### Plot showing estimates and CIs for each city 

```{r plot}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) + 
  labs(
    title = "Estimates and confidence intervals for each city",
    x = "City", 
    y = "Estimate"
  )
```


## PROBLEM 2 

### Creating a dataframe containing all file names using list.files

```{r file_names}
file_names_df = 
  tibble(
    file = list.files("data/zip_data/"))
```

### Iterating over file names 

```{r file_iteration, message = FALSE, warning = FALSE}
# creating iteration function 
file_iteration_function = function(file_name) {
  
  data = 
    read_csv(file = paste0("data/zip_data/", file_name))
  
}

# iterating over file names, saving result as new variable in dataframe
participants_df = 
  file_names_df %>% 
  mutate(
    weeks_data = map(file, file_iteration_function)
  ) %>% 
  unnest(weeks_data)
```

### Tidying dataframe 

```{r tidy_df}
# tidying the resulting dataframe
tidy_participants_df = 
  participants_df %>%
  janitor::clean_names() %>% 
  mutate(
    study_arm = str_extract(file, "con|exp"),
    study_arm = case_when(
      study_arm == "con" ~ "control",
      study_arm == "exp" ~ "experimental"), 
    subject_id = str_replace(file, ".csv", "")
  ) %>% 
  select(-file) %>% 
  relocate(subject_id, study_arm, everything()) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observation_data"
  ) %>% 
  mutate(
    week = factor(week,levels = c("week_1", "week_2", "week_3", "week_4",
                                  "week_5", "week_6", "week_7", "week_8"))
  )
```

### Creating spaghetti plot showing observations on each subject over time 

```{r spaghetti_plot}
tidy_participants_df %>% 
  ggplot(aes(x = week, y = observation_data, color = subject_id)) + 
  geom_line(aes(group = subject_id)) + 
  facet_grid(.~ study_arm) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  labs(
    title = "Observation data on each subject over time",
    x = "Week", 
    y = "Observation data"
  ) + 
  theme(legend.position = "right")
```

The observation data for experimental subjects over time is higher than the observation data for control subjects over time. The observation data for experimental subjects generally increases over time, while the observation data for control subjects appears to stay relatively stable over time. 


## PROBLEM 3 

### Loading the iris dataset 

```{r loading_iris}
library(tidyverse)

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

### Writing function to replace missing values 

```{r iris_missing_function}
iris_missing_function = function(x) {
  
  if (is.numeric(x)) {
    x[is.na(x)] = mean(x, na.rm = TRUE)
  } else if (is.character(x)) { 
    x[is.na(x)] = "virginica"
    } 
  
  return(x)
  
}
```

### Iterating across columns of iris_with_missing using a map statement

```{r column_iteration}
for (i in 1:5) {
  iris_with_missing[i] = map(iris_with_missing[i], ~iris_missing_function(.x))
}

# displaying final iris_with_missing dataset 
iris_with_missing
```
